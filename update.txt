**22/07**

    - Reminder from the supervisor to keep an update.txt file on Git with daily progress because of remote work.
    - Told to re-test speech-to-speech conversion, justify decisions in writing, and improve TTS sync with video start.
    - Started working on the script to detect the start of speech in videos.
    - Began refactoring code in various units and classes for better structure and clarity.
    - Added comments to the code for better documentation and readability.

---

**23/07**

    - Continued working on the speech detection script.
    - ##Encountered an issue##: the script always records 29 seconds instead of 9. Tried to figure out the issue but no luck yet.
    - Tweaked the UI to include an iteration field for creating multiple output videos in a single request. This should make testing more efficient.
    - More code refactoring and commenting.

---

**24/07**:

    - More UI improvements.
    - Added time estimation to the UI to give a better idea of processing times.
    - Documented the UI changes and why they were made.
    - Continued code refactoring and adding comments.
    - Started digging into DeepFaceLab's repo to understand the technologies they use.

---

**25/07**

    - Tried re-testing the speech-to-speech conversion.
    - Still running into errors; the library seems unstable.
    - Decided to pause further testing on speech-to-speech conversion until there's a more stable library version.
    - Wrote down why this decision was made.
    - Kept researching DeepFaceLab's tech, focusing on how they implement things.

---

**26/07**

    - Finalized and tested the UI changes; everything works as expected.
    - Wrote up justifications for each decision made this week, including:
        - The instability of the speech-to-speech conversion library.
        - Adding the iteration field and time estimation in the UI.
        - Issues with the speech detection script.
    - Compiled and committed all updates to the Git repository.
    - Continued looking into DeepFaceLab's tech and documenting findings.
    - Finished code refactoring and made sure all relevant sections are well-commented

---

**29/07**

    - Got new instructions and guidance :
        - As previously mentioned, need to emphasize more on researching alternatives technologies even if they don't exactly fit my our use-case.
        - Keep 3-4 exemple french target audio files, and automate cross-testing between all 12 possible voice combinations.
        - Prepare a video directory in Git, with at least 4 instances per voice combination, good and bad.
        - Further research wav2Lip and babelfish as well as the Sync API as possible technologies as well as other STS models on Huggingface for exemple.
        - If TTS' by Coqui lib failed inference for freevc24, attempt to use the docker version or start on a new clean env.
        - Research https://huggingface.co/nvidia/bigvgan_v2_44khz_128band_512x for post-processing
        - Research https://synclabs.so/ for possible lip-syncing API

---

**08/08**  
- Had a meeting with my mentor. He suggested focusing on lip-syncing as he felt the audio part was good enough for now. I disagreed but will proceed as instructed.  
- Spent the day updating output file names to prevent overwriting and keep a record of all test outputs.

---

**09/08**  
- Continued working on Wav2Lip setup.  
- Realized that Wav2Lip only supports Python 3.6, which wasn't clearly specified in the README.  
- The initial installation failed due to having the wrong Python version.

---

**10/08**  
- Installed Python 3.6.0, but ran into another issue: Torch 1.1.0 isn't available for Python 3.6.0.  
- Considered needing a higher version of Python 3.6, but still unsure of the exact version required.  
- Spent time searching the issues tab on the Wav2Lip repository for solutions, but most issues were minor and unhelpful.

---

**11/08**  
- Found an issue in the Wav2Lip repo about running it on Windows. The suggested solution was to use WSL.  
- Frustrated by the prospect of needing to set up a Linux VM or dual boot just to test part of the project.  
- Ventured into Linux setup considerations, knowing the pain of dealing with missing DLLs and NVIDIA/CUDA issues on Linux.

---

**12/08**  
- Debated the best approach to proceed: whether to set up a Linux VM, dual boot, or continue struggling with the Windows setup.  
- Decided to start the process of setting up a Linux environment while considering potential workarounds for the NVIDIA/CUDA issues.

---

**13/08**  
- Continued the setup of the Linux environment, working through dependency issues and preparing for potential CUDA/NVIDIA challenges.  
- Planned to test Wav2Lip on the new setup as soon as everything is configured correctly.

---